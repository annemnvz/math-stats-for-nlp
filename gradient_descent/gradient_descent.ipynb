{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Gradient descent - continuation\n",
    " \n",
    " ##  Multiple inputs\n",
    "\n",
    "Imagine we have one review, that had a *positive* label and the occurrences for words *beatifully, masterpiece, movie, dull,* and *disappointing* were 1 (yes) , 0 (no),  1,    0 and   0, respectively. That means:\n",
    "\n",
    "Input values: $\\mathbf{x} = (1,  0, 1, 0, 0)'$\n",
    "\n",
    "True label: $y = 1$\n",
    "\n",
    "- Consider weights $A=(-0.46, -0.25,  0.14,  0.82, -0.59)$. What is the corresponding error? \n",
    "- Update the weights with step $\\alpha = 0.1$. What are the final weights?\n",
    "- If you change the starting weights, do you get the same final weights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1)\n",
      "(5,)\n",
      "Weight = [-0.46 -0.25  0.14  0.82 -0.59] ; gap =  [-1.32] ; error =  [1.7424]\n",
      "Weight = [[ 0.2  -0.25  0.8   0.82 -0.59]] ; gap =  [[-1.11022302e-16]] ; error =  [[1.23259516e-32]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "input_data = np.array([[1], [0], [1], [0], [0]])\n",
    "goal = 1\n",
    "weights = np.array([-0.46, -0.25,  0.14,  0.82, -0.59])\n",
    "print(input_data.shape)\n",
    "print (weights.shape)\n",
    "\n",
    "prediction = np.matmul(weights, input_data)    # <-- Prediction #weights @ input_data #weights.dot(input_data)\n",
    "gap =  prediction - goal  # <-- Difference between the prediction and the goal to predict\n",
    "error = gap**2\n",
    "print('Weight =', weights, '; gap = ', gap, '; error = ', error)\n",
    "\n",
    "# To update the weights\n",
    "alpha = 0.1\n",
    "Ni =  200  #<-- Number of iterations\n",
    "for iteration in range(200):\n",
    "    weights = weights - alpha*gap*input_data.T # 1 x 5 shape\n",
    "    # update the prediction, gap, error\n",
    "    prediction = np.matmul(weights, input_data)\n",
    "    gap = prediction - goal\n",
    "    error = gap**2\n",
    "print('Weight =', weights, '; gap = ', gap, '; error = ', error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extend this example for 4 the following instances:\n",
    "$$\n",
    "   \\begin{array}{l|cccccc}\n",
    "   & \\mbox{beatifully}& \\mbox{masterpiece} & \\mbox{movie} & \\mbox{dull} &\\mbox{disappointing} & \\mbox{ Output}\\\\\n",
    "r1     &     1      &     0 &    1 &   0    &         0 & 1\\\\\n",
    "r2     &     0   &        1  &   1 &   0   &          0 & 1\\\\\n",
    "r3     &     0     &      0  &   1 &   1   &          0 & 0\\\\\n",
    "r4     &     1    &       0  &   1 &   1   &          1 & 0\\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Start with weights ð´=(âˆ’0.46,âˆ’0.25,0.14,0.82,âˆ’0.59) and step $\\alpha = 0.1$. What is the total error at the end of 200 iterations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight = [[ 0.51200102  0.51199212  0.48800449 -0.48799866 -0.51201001]] ; gap =  [[-5.26551771e-06]] ; error =  0\n",
      "Predictions =\n",
      " [[ 1.00000551e+00  9.99996615e-01  5.82833817e-06 -3.15931063e-06]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array([[1, 0, 0, 1], [0, 1, 0, 0], [1, 1, 1, 1], [0, 0, 1, 1], [0, 0, 0, 1]])\n",
    "Y = np.array([[1],[1], [0], [0]])\n",
    "weights = np.array([-0.46, -0.25,  0.14,  0.82, -0.59])\n",
    "\n",
    "\n",
    "alpha = 0.1\n",
    "Ni =  200  #<-- Number of iterations\n",
    "for iteration in range(200):\n",
    "    error_for_all = 0\n",
    "    for ind in range(4):\n",
    "        input_data = X[:, [ind]]\n",
    "        goal = Y[ind]\n",
    "        prediction = np.matmul(weights, input_data)\n",
    "        gap = prediction - goal\n",
    "        error = gap**2\n",
    "        weights = weights - alpha*gap*input_data.T # 1 x 5 shape\n",
    "        prediction = np.matmul(weights, input_data)\n",
    "        \n",
    "print('Weight =', weights, '; gap = ', gap, '; error = ', error_for_all)\n",
    "print('Predictions =\\n', np.matmul(weights, X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##  Multiple inputs and multiple outputs\n",
    "\n",
    "\n",
    "Input values: $\\mathbf{x} = (1.5, 0.65, 1.3)'$\n",
    "\n",
    "True label: $\\mathbf{y} = (1.2, 1.4)'$\n",
    "\n",
    "Starting weights $A = \\left(\\begin{array}{ccc}\n",
    "1 & 1 &1.1\\\\\n",
    "1 & 3 & 2\\\\\n",
    "\\end{array}\\right)$\n",
    "\n",
    "- Calculate the first prediction. What is the dimension? Calculate the corresponding error.\n",
    "- Iterate 200 times the gradient descent with $\\alpha= 0.1$. What are the final weights and corresponding error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "Prediction:  [[3.58]\n",
      " [6.05]] \n",
      "\n",
      "Gap:\n",
      " [[2.38]\n",
      " [4.65]] \n",
      "\n",
      "Gap**2:\n",
      "  [[ 5.6644]\n",
      " [21.6225]] \n",
      "\n",
      "Sum Gap**2:  [27.2869] \n",
      "\n",
      "Weight = [[1.  1.  1.1]\n",
      " [1.  3.  2. ]] \n",
      " gap =  [[2.38]\n",
      " [4.65]] \n",
      " error =  [27.2869] \n",
      "\n",
      "Weight = [[ 0.18166189  0.64538682  0.39077364]\n",
      " [-0.59885387  2.30716332  0.61432665]] \n",
      " gap =  [[-2.22044605e-16]\n",
      " [ 0.00000000e+00]] \n",
      " error =  [4.93038066e-32] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "input_data = np.array([[1.5], [0.65], [1.3]])\n",
    "goal = np.array([[1.2], [1.4]])\n",
    "weights = np.array([[1, 1, 1.1], [1, 3, 2]])\n",
    "#print (goal.shape)\n",
    "\n",
    "prediction =  np.matmul(weights, input_data)# <-- Calculate the prediction\n",
    "print('Prediction: ', prediction, '\\n')\n",
    "\n",
    "gap = prediction - goal # <-- Difference between prediction anf goal to predict\n",
    "print('Gap:\\n', gap, '\\n')\n",
    "print('Gap**2:\\n ', gap**2, '\\n')\n",
    "print('Sum Gap**2: ', sum(gap**2), '\\n')\n",
    "\n",
    "error = sum(gap**2) # <--  Calculate the error\n",
    "print('Weight =', weights, '\\n gap = ', gap, '\\n error = ', error, '\\n')\n",
    "\n",
    "Ni = 200\n",
    "# update the weight\n",
    "for iteration in range(Ni):\n",
    "    prediction =  np.matmul(weights, input_data)\n",
    "    gap = prediction - goal\n",
    "    error = sum(gap**2)\n",
    "    weights = weights - alpha*np.matmul(gap, input_data.T)\n",
    "    \n",
    "print('Weight =', weights, '\\n gap = ', gap, '\\n error = ', error, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Adding a second layer\n",
    "\n",
    "Input values: $\\mathbf{x} = (1, 0, 1)'$\n",
    "\n",
    "True label: $y = 1$\n",
    "\n",
    "We will build an intermediate layer of dimension 4, $F(\\mathbf{x}) = B(ReLU(A\\mathbf{x}))$.\n",
    "\n",
    "Starting weights $A = \\left(\\begin{array}{ccc}\n",
    "0.17 & 0.71 & -0.20\\\\\n",
    "0.44 & 0.82 & 0.08\\\\\n",
    "1.00 & 0.63 & -0.16\\\\\n",
    "-0.40 & 0.31 & 0.37\\\\\n",
    "\\end{array}\\right)$ and $B= (-0.59 \\; 0.76 \\; 0.95  \\; 0.34)$\n",
    "\n",
    "- Compute the first prediction, layer by layer. What is the gap? And the error?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First layer:  [[-0.  ]\n",
      " [ 0.52]\n",
      " [ 0.84]\n",
      " [-0.  ]]\n",
      "Prediction Last layer:  [[1.1932]]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-600059de7867>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mgoal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[0mgap\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mpred\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mgoal\u001b[0m   \u001b[1;31m# <--  Gap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mgap\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m  \u001b[1;31m# <-- error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.array([[1], [0], [1]]) # Input data\n",
    "y = 1 # <-- Goal to predict\n",
    "# Starting weights\n",
    "A = np.array([[0.17, 0.71, -0.2], [0.44, 0.82 , 0.08], [1.00, 0.63, -0.16], [-0.40, 0.31 , 0.37]] ) # 4 x 3\n",
    "B = np.array([[-0.59, 0.76, 0.95, 0.34]])\n",
    "\n",
    "#print(A) matrix\n",
    "#print(B) vector\n",
    "\n",
    "def ReLU(x):\n",
    "    return (x >= 0)*x  # <-- ReLU function\n",
    "def derivReLU(x):\n",
    "    return 1*(x > 0) # <-- Derivative of ReLU\n",
    "\n",
    "#print(\"A\", A.shape)\n",
    "#A=(4,3) (4rows, 3col)\n",
    "#print(\"X\", x.shape) \n",
    "#X=(3,1)\n",
    "#print(\"B\", B.shape)\n",
    "#B=(1,4) (1 row, 4 col)\n",
    "\n",
    "input_data = x\n",
    "layer1 = ReLU(np.matmul(A, input_data))#(4,3)*(3,1)    # <-- # Prediction for first layer\n",
    "print('First layer: ', layer1 )\n",
    "#print(\"First layer sh\", layer1.shape) #layer1=(4,1)\n",
    "\n",
    "pred =  np.matmul(B, layer1)   # <--  Prediction for the second layer\n",
    "print('Prediction Last layer: ', pred)\n",
    "#print(\"Sec layer sh\", pred.shape) #pred=(1,1)\n",
    "\n",
    "goal = y\n",
    "#y = 1\n",
    "gap =  pred - goal   # <--  Gap\n",
    "error =  gap**2  # <-- error\n",
    "print('Gap= ', gap, 'Error = ', error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the weights: first, the weights of the second layer, then those of the first one. (Use step $\\alpha = 0.1$ and 200 iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final weights: [[ 0.17        0.71       -0.2       ]\n",
      " [ 0.40114708  0.82        0.04114708]\n",
      " [ 0.9517511   0.63       -0.2082489 ]\n",
      " [-0.4         0.31        0.37      ]] [[-0.59        0.73442204  0.90809338  0.34      ]]\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.1 # <-- step of the function\n",
    "Ni = 200 #<-- Number of iterations\n",
    "\n",
    "def ReLU(x):\n",
    "    return (x >= 0)*x\n",
    "def derivReLU(x):\n",
    "    return 1*(x > 0)\n",
    "\n",
    "input_data = x\n",
    "goal = y\n",
    "for iteration in range(Ni):\n",
    "    pre_layer1 =  np.matmul(A, input_data)# <-- Ax product, pre-layer 1 \n",
    "    layer1 =  ReLU(pre_layer1)   # <-- At layer 1\n",
    "    pred =  np.matmul(B, layer1)    # <-- Prediction at layer 2\n",
    "    gap = pred - goal\n",
    "    error = gap**2\n",
    "    # Update second layer's weights\n",
    "    B = B - alpha * gap*layer1.T\n",
    "    # Update first layer's weights in two steps\n",
    "    aux = np.multiply(B.T, derivReLU(pre_layer1)) # <-- Multiply arguments element-wise, B and derivReLU evaluated at Ax\n",
    "    A =  A - alpha * gap* np.matmul(aux, input_data.T)# <-- update A\n",
    "print('Final weights:', A, B)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the procedure for several units of observations:\n",
    "Input values: $X = \\left(\\begin{array}{ccc}\n",
    "1 & 0  &1 \\\\\n",
    "0 &1 &1\\\\\n",
    "0 & 0 & 1\\\\\n",
    "1 & 1 & 1\\\\\n",
    "\\end{array}\\right)$\n",
    "\n",
    "True label: $\\mathbf{y} = (1, 1, 0, 0)'$\n",
    "\n",
    "Use the same structure and the same starting weights with step $\\alpha = 0.1$ and 200 iterations.\n",
    "Starting weights $A = \\left(\\begin{array}{ccc}\n",
    "0.17 & 0.71 & -0.20\\\\\n",
    "0.44 & 0.82 & 0.08\\\\\n",
    "1.00 & 0.63 & -0.16\\\\\n",
    "-0.40 & 0.31 & 0.37\\\\\n",
    "\\end{array}\\right)$ and $B= (-0.59 \\; 0.76 \\; 0.95  \\; 0.34)$\n",
    "\n",
    "\n",
    "What is the error? What are the predictions you get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final weights: [[ 8.57771315e-01  1.13745339e+00 -8.57745896e-01]\n",
      " [ 5.05788348e-01  7.46415148e-01  5.03677531e-02]\n",
      " [ 1.13535948e+00  5.10178812e-01 -6.28361315e-04]\n",
      " [-8.03932850e-01  8.04785876e-01 -9.64607733e-04]] [[-1.42121403  0.34084107  0.7127118   0.94780922]]\n",
      "Total error= 0.0002986637716262265\n",
      "Predictions:\n",
      " [[ 9.98260981e-01  9.99083950e-01  1.71673990e-02 -2.84334271e-04]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.array([[1, 0, 0, 1], [0, 1, 0, 1], [1, 1, 1, 1]]) # <-- Input data\n",
    "y = np.array([[1], [1], [0], [0]]) # <-- Goal to predict\n",
    "\n",
    "A = np.array([[0.17, 0.71, -0.2], [0.44, 0.82 , 0.08], [1.00, 0.63, -0.16], [-0.40, 0.31 , 0.37]] ) # 4 x 3\n",
    "B = np.array([[-0.59, 0.76, 0.95, 0.34]]) #1x4\n",
    "\n",
    "def ReLU(x):\n",
    "    return (x >= 0)*x\n",
    "def derivReLU(x):\n",
    "    return 1*(x > 0)\n",
    "\n",
    "#print(\"X\", x.shape) #(3,4)\n",
    "#print(\"Y\", y.shape) #(4,1)\n",
    "#print(\"A\", A.shape) #(4,3)\n",
    "#print(\"B\", B.shape) #(1,4) vector\n",
    "\n",
    "alpha = 0.1 # <- step of the function\n",
    "Ni = 200\n",
    "\n",
    "for iteration in range(Ni):\n",
    "    for ind in range(4):\n",
    "        input_data = x[:, [ind]] #(3,1[each 1 out of 4]))\n",
    "        goal = y[ind] #(4,1)\n",
    "        #print(\"goal\", goal.shape)\n",
    "        pre_layer1 =  np.matmul(A, input_data)#(4,3)*(3,1)[*4 times]\n",
    "        layer1 =  ReLU(pre_layer1)   # (4,1)*[4 times]\n",
    "        pred =  np.matmul(B, layer1)    #(1,4)*(4,1)=(1,1)*[4 times]\n",
    "        #print(pred.shape) \n",
    "        #print(pred)\n",
    "        gap = pred - goal #(1,1)-(4,1)\n",
    "        #print(\"gap:\",gap)\n",
    "        #print(gap.shape) #(1,1) many times?\n",
    "        error = gap**2\n",
    "        # Update second layer's weights\n",
    "        B = B - alpha * gap*layer1.T\n",
    "        # Update first layer's weights in two steps\n",
    "        aux = np.multiply(B.T, derivReLU(pre_layer1)) # <-- Multiply arguments element-wise, B and derivReLU evaluated at Ax\n",
    "        A =  A - alpha * gap* np.matmul(aux, input_data.T)# <-- update A\n",
    "print('Final weights:', A, B)\n",
    "\n",
    "\n",
    "pred = np.matmul(B, ReLU(np.matmul(A, x)))    # <-- Final predictions\n",
    "gap2 = (pred- y.T)**2\n",
    "total_error = np.sum(gap2)\n",
    "print('Total error=', total_error)\n",
    "print('Predictions:\\n', pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional.** Repeat the above procedure for different values of $\\alpha$ and different number of iterations. Choose the best one. What are the predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.37250766e-01 1.78290610e-01 5.17867136e-04]\n",
      " [1.01656591e-05 2.93375503e-09 6.23380209e-27]\n",
      " [5.84476428e-29 2.55170747e-24 2.60761676e-02]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "A = np.array([[0.17, 0.71, -0.2], [0.44, 0.82 , 0.08], [1.00, 0.63, -0.16], [-0.40, 0.31 , 0.37]] ) # 4 x 3\n",
    "B = np.array([[-0.59, 0.76, 0.95, 0.34]])\n",
    "x = np.array([[1, 0, 0, 1], [0, 1, 0, 1], [1, 1, 1, 1]])  # <-- Input values\n",
    "y = np.array([[1], [1], [0], [0]]) # <-- Goal to predict\n",
    "\n",
    "def ReLU(x):\n",
    "    return (x >= 0)*x\n",
    "def derivReLU(x):\n",
    "    return 1*(x > 0) #sarrera bektorearen dimentsioak mantentzen ditu\n",
    "\n",
    "alpha_values = np.array([0.01, 0.1, 0.2]) # <- step of the function\n",
    "Ni_values = np.array([100, 200, 1000]) # <-- Number of iteration\n",
    "error = np.zeros(shape=(3,3))\n",
    "for a in range(len(alpha_values)):\n",
    "    alpha = alpha_values[a]\n",
    "    for ni in range(len(Ni_values)):\n",
    "        Ni = Ni_values[ni]\n",
    "        for iteration in range(Ni):\n",
    "            error[[a], [ni]] = 0\n",
    "            for row_index in range(4):\n",
    "                input_data = x[:, [row_index]]\n",
    "                pre_layer1 = np.matmul(A, input_data)\n",
    "                layer1 = ReLU(pre_layer1)\n",
    "                pred = np.matmul(B, layer1)\n",
    "                goal = y[row_index]\n",
    "                gap = pred - goal\n",
    "                error[[a], [ni]] =  error[[a], [ni]] +  gap*gap\n",
    "                B = B - alpha * gap * layer1.T # 1 x 3 matrix\n",
    "                aux = np.multiply(B.T, derivReLU(np.matmul(A, input_data)))\n",
    "                A = A - alpha * gap * np.matmul(aux, input_data.T)\n",
    "print(error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "96a55daf58faaef8a1b96e459858a5fcbfc9b90e0725bdbc6027ea64829581b1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
